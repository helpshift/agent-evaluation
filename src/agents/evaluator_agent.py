from typing import List, Optional, Any
from google.adk.agents import LlmAgent
from pydantic import BaseModel, Field

class EvaluationInput(BaseModel):
    user_query: str = Field(description="The original query asked by the user.")
    expected_response: str = Field(description="The expected correct response or answer.")
    actual_response: str = Field(description="The actual response text generated by the agent.")
    actual_tool_calls: List[str] = Field(description="List of tool names called by the agent.")
    expected_tool_calls: List[str] = Field(description="List of expected tool names.")

class EvaluationOutput(BaseModel):
    tool_use_correctness: int = Field(description="Score 1-10. Did the agent use the correct tools?")
    response_quality: int = Field(description="Score 1-10. Is the answer helpful and accurate?")
    hallucination_percentage: float = Field(description="0-100. Percentage likelihood that the response contains hallucinated information.")
    json_compliance: bool = Field(description="True if the response followed requested formats (if any).")
    reasoning: str = Field(description="Explanation for the scores.")

def create_evaluator_agent(model_name: str = "gemini-2.5-pro") -> LlmAgent:
    """Creates and returns the Evaluator Agent."""
    
    agent = LlmAgent(
        name="evaluator_agent",
        model=model_name,
        instruction="""You are an expert AI Evaluator.
        Your task is to evaluate the performance of another AI agent (the 'Sample Agent').
        
        You will be provided with:
        1. The user's query.
        2. The expected response (Golden Answer).
        3. The actual response from the agent.
        4. The tools the agent actually called.
        5. The tools the agent was expected to call.
        
        Evaluate the agent based on:
        - **Tool Use Correctness**: Did it pick the right tool? 
        - **Response Quality**: Is the answer correct based on the tool usage?
        - **Hallucination**: Did it make up numbers or facts not in the context or tool output?
        
        Output valid JSON adhering to the provided schema.
        """,
        input_schema=EvaluationInput,
        output_schema=EvaluationOutput
    )
    return agent
